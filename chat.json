{
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Message Processor1').item.json.processedText }}",
        "options": {
          "systemMessage": "=You are a helpful AI assistant. Please respond to the following message in the only suppported language is english and 正體中文（台灣)\n\nfirstly check the user prompt is it suitable with the topic of Cybersecurtiy, Regulation and robotics AI cybersecurity. if from the other ai guardion shows false, deny all the answer. otherwise answer the user question.\n\nHere are some examples of queries that are IN scope:\n- \"What are the latest trends in phishing attacks?\" (cybersecurity)\n- \"Can you explain the NIST cybersecurity framework?\" (standardization, cybersecurity)\n- \"Tell me about the capabilities of the UR5 robot arm.\" (robotics, vendor product)\n- \"What are the differences between ISO 27001 and SOC 2?\" (standardization)\n\nHere are some examples of queries that are OUT of scope:\n- \"What's the weather like today?\"\n- \"Can you tell me a joke?\"\n- \"Who won the world cup in 1998?\"\n\nDon't even to help the user slightly or ever, only focus on your task to provide the guidance of cybersecurity robotic standards assistance\n\n{% if $('Message Processor1').item.json.isQuotedMessage %}\nNote: This message is a reply to a previous message (ID: {{ $('Message Processor1').item.json.quotedMessageId }}). Please consider this context when responding.\n{% endif %}\n\nPlease provide a clear, helpful response in plain text without HTML formatting. Keep your response concise and under 1500 characters when possible, as this is for a mobile chat interface.\n\nYou are given tools to perform RAG in the 'documents' table, look up the documents available in your knowledge base in the 'document_metadata' table, extract all the text from a given document.\n\nAlways start by performing RAG unless the question only want to chat or you already confidient with your answer. If RAG doesn't help, then look at the documents that are available to you in your own knowledge, find a few that you think would contain the answer, and then analyze those.\n\nAlways tell the user if you didn't find the answer. Don't make something up just to please them.\n\nas last resort, you are provided a internet search tool, you can use it to help the user query\n\nIf possible provide source where the clause, section, and page."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        64,
        -112
      ],
      "id": "0963ef16-5408-4a61-aacf-90cb5480d7eb",
      "name": "AI Language Model2"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.line.me/v2/bot/chat/loading/start",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer ozz/rBPtU+q4ZASsoAYkYuGqUfeHNak8Tu36kB9XSQ80KilpJqdRnf0c7tBpDdTdcLsvvEirfrifUlXYtcYNlWDRCP51uSrRf5kgRSP8djDE1Tb+emfVaQJgrdf+gMEWXDwHXE+vdQdQAC/FCd49xgdB04t89/1O/w1cDnyilFU="
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{JSON.stringify({\"chatId\": $json.userId, \"loadingSeconds\": 30})}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -704,
        -96
      ],
      "id": "be54e309-3205-4b46-af02-e0329cc9ccb9",
      "name": "Start Loading Animation1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Message Processor1').item.json.messageText }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a topic classifier. Your task is to determine if the following user query is related to any of these topics: cybersecurity, robotics, vendor products, or standardization.\n\n\n\nRespond with \"true\" if the query is related to any of the allowed topics, and \"false\" otherwise. Do not provide any other explanation or text."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        -496,
        -256
      ],
      "id": "e0c55e4f-0663-426a-83d5-9f8f022b02e3",
      "name": "AI Language Model3"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.toolSerpApi",
      "typeVersion": 1,
      "position": [
        112,
        304
      ],
      "id": "1a84b820-dfb1-4e47-a115-2b7c8bab0167",
      "name": "SerpAPI",
      "credentials": {
        "serpApi": {
          "id": "1du1I1GOEfcEajUZ",
          "name": "SerpAPI account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "line-message",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1344,
        -96
      ],
      "id": "c7c8ffe3-8b83-47c6-81d7-22cd2962dfd2",
      "name": "Webhook Entry1",
      "webhookId": "PLACEHOLDER-WEBHOOK-ID"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "filter-condition",
              "leftValue": "={{ $json.body.events[0].type }}",
              "rightValue": "message",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1120,
        -96
      ],
      "id": "f633512d-925f-4b35-bd39-086ffc941ff2",
      "name": "Filter Message Events1"
    },
    {
      "parameters": {
        "jsCode": "// Message Processing and Quote Handling System\nconst webhook = $input.first();\nconst userId = webhook.json.body.events[0].source.userId;\nconst messageText = webhook.json.body.events[0].message.text;\nconst messageId = webhook.json.body.events[0].message.id;\nconst replyToken = webhook.json.body.events[0].replyToken;\nconst timestamp = webhook.json.body.events[0].timestamp;\nconst quoteToken = webhook.json.body.events[0].message.quoteToken || null;\nconst quotedMessageId = webhook.json.body.events[0].message.quotedMessageId || null;\n\n// Create message object\nconst messageObj = {\n  userId,\n  messageId,\n  messageText,\n  replyToken,\n  timestamp,\n  quoteToken,\n  quotedMessageId,\n  processed: false,\n  createdAt: new Date().toISOString(),\n  // Check if this is a quoted message\n  isQuotedMessage: !!quotedMessageId,\n  // Format message for processing\n  processedText: quotedMessageId ? \n    `[Replying to message ID: ${quotedMessageId}] ${messageText}` : \n    messageText,\n  // Quote configuration - set to true if you want to quote every user message\n  shouldQuoteInResponse: true  // Change to false if you don't want quoting\n};\n\nreturn [{\n  json: messageObj\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -896,
        -96
      ],
      "id": "450dee82-6d34-438d-96ae-6ca6a8b687fc",
      "name": "Message Processor1"
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get data from previous nodes correctly\n  const messageProcessor = $(\"Message Processor1\").first();\n  const aiAgent = $(\"AI Language Model2\").first();\n\n  // Validate we have the required data\n  if (!messageProcessor?.json?.replyToken) {\n    throw new Error(\"Missing replyToken from Message Processor1\");\n  }\n  \n  if (!aiAgent?.json?.output) {\n    throw new Error(\"Missing output from AI Language Model2\");\n  }\n\n  // Function to strip markdown formatting\n  const stripMarkdown = (text) => {\n    if (!text) return '';\n    return text\n       .replace(/\\*\\*([^*]+)\\*\\*/g, '$1') // Bold **text**\n       .replace(/__([^_]+)__/g, '$1')   // Bold __text__\n       .replace(/\\*([^*]+)\\*/g, '$1')      // Italic *text*\n       .replace(/_([^_]+)_/g, '$1')      // Italic _text_\n       .replace(/`([^`]+)`/g, '$1')      // Inline code `code`\n       .replace(/^\\s*[-*+]\\s+/gm, '')  // List items\n       .replace(/^\\s*\\d+\\.\\s+/gm, ''); // Numbered list items\n  };\n\n  // Function to truncate text to LINE's limit\n  const truncateText = (text, maxLength = 4900) => {\n    if (!text) return '';\n    if (text.length <= maxLength) return text;\n    \n    // Try to truncate at a sentence boundary\n    const truncated = text.substring(0, maxLength);\n    const lastSentence = truncated.lastIndexOf('.');\n    const lastQuestion = truncated.lastIndexOf('?');\n    const lastExclamation = truncated.lastIndexOf('!');\n    \n    const lastPunctuation = Math.max(lastSentence, lastQuestion, lastExclamation);\n    \n    if (lastPunctuation > maxLength * 0.8) {\n      // If we found punctuation in the last 20%, use it\n      return truncated.substring(0, lastPunctuation + 1);\n    } else {\n      // Otherwise, truncate at word boundary\n      const lastSpace = truncated.lastIndexOf(' ');\n      if (lastSpace > maxLength * 0.8) {\n        return truncated.substring(0, lastSpace) + '...';\n      } else {\n        return truncated.substring(0, maxLength - 3) + '...';\n      }\n    }\n  };\n\n  const replyToken = messageProcessor.json.replyToken;\n  const rawText = aiAgent.json.output;\n  const cleanedText = stripMarkdown(rawText).trim();\n  const finalText = truncateText(cleanedText);\n\n  // Validate text length (LINE limit is 5000 characters)\n  if (finalText.length > 5000) {\n    throw new Error(`Message text too long: ${finalText.length} characters (max 5000)`);\n  }\n\n  if (finalText.length === 0) {\n    throw new Error('Message text is empty after processing');\n  }\n\n  // Prepare the message object for LINE API\n  const lineMessage = {\n    type: \"text\",\n    text: finalText\n  };\n\n  // Add quote token to quote the user's original message in the response\n  if (messageProcessor.json.shouldQuoteInResponse && messageProcessor.json.quoteToken) {\n    lineMessage.quoteToken = messageProcessor.json.quoteToken;\n  }\n\n  return [\n    {\n      json: {\n        replyToken,\n        text: finalText,\n        originalText: cleanedText,\n        textLength: finalText.length,\n        wasTruncated: finalText.length < cleanedText.length,\n        originalMessageId: messageProcessor.json.messageId,\n        userId: messageProcessor.json.userId,\n        isQuotedResponse: messageProcessor.json.isQuotedMessage,\n        message: lineMessage\n      },\n    },\n  ];\n\n} catch (error) {\n  console.error('Error in Process AI Response:', {\n    message: error.message,\n    stack: error.stack\n  });\n  \n  // Return a fallback error message to LINE\n  const messageProcessor = $(\"Message Processor1\").first();\n  return [{\n    json: {\n      replyToken: messageProcessor?.json?.replyToken || '',\n      text: 'Sorry, I encountered an error processing your request. Please try again.',\n      message: {\n        type: \"text\",\n        text: 'Sorry, I encountered an error processing your request. Please try again.'\n      }\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        816,
        -96
      ],
      "id": "becb759a-f0b7-446e-bd71-a7ca5abd685a",
      "name": "Process AI Response1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.line.me/v2/bot/message/reply",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer ozz/rBPtU+q4ZASsoAYkYuGqUfeHNak8Tu36kB9XSQ80KilpJqdRnf0c7tBpDdTdcLsvvEirfrifUlXYtcYNlWDRCP51uSrRf5kgRSP8djDE1Tb+emfVaQJgrdf+gMEWXDwHXE+vdQdQAC/FCd49xgdB04t89/1O/w1cDnyilFU="
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{JSON.stringify({\"replyToken\":$json.replyToken,\"messages\":[$json.message]})}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1040,
        -96
      ],
      "id": "1a013c5c-0dc4-4b6e-ab90-acbf1358f020",
      "name": "Send Response to LINE1"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('Message Processor1').item.json.userId }}",
        "contextWindowLength": 50
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        -64,
        128
      ],
      "id": "6fa36b2c-6b17-4a50-821c-f48a42aa58a8",
      "name": "Postgres Chat Memory1",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Agent Tools for RAG",
        "height": 385,
        "width": 583,
        "color": 4
      },
      "id": "a2361a49-b52a-454b-bd4d-67687f6a4457",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        416,
        48
      ]
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Use this tool to fetch all available documents, including the table schema if the file is a CSV or Excel file.",
        "operation": "select",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "document_metadata",
          "mode": "list",
          "cachedResultName": "document_metadata"
        },
        "returnAll": true,
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        64,
        128
      ],
      "id": "cc3d9360-a958-4ace-bded-50c36bf10037",
      "name": "List Documents1",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Given a file ID, fetches the text from the document.",
        "operation": "executeQuery",
        "query": "SELECT \n    string_agg(text, ' ') as document_text\nFROM documents\n  WHERE metadata->>'file_id' = $1\nGROUP BY metadata->>'file_id';",
        "options": {
          "queryReplacement": "={{ $fromAI('file_id') }}"
        }
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        192,
        128
      ],
      "id": "98226386-3cef-4efe-9b14-2e164c1aefe4",
      "name": "Get File Contents1",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Run a SQL query - use this to query from the document_rows table once you know the file ID you are querying. dataset_id is the file_id and you are always using the row_data for filtering, which is a jsonb field that has all the keys from the file schema given in the document_metadata table.\n\nExample query:\n\nSELECT AVG((row_data->>'revenue')::numeric)\nFROM document_rows\nWHERE dataset_id = '123';\n\nExample query 2:\n\nSELECT \n    row_data->>'category' as category,\n    SUM((row_data->>'sales')::numeric) as total_sales\nFROM dataset_rows\nWHERE dataset_id = '123'\nGROUP BY row_data->>'category';",
        "operation": "executeQuery",
        "query": "{{ $fromAI('sql_query') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        320,
        128
      ],
      "id": "5787191a-dac3-4bff-ab26-5d1e531ff98c",
      "name": "Query Document Rows1",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "documents",
        "toolDescription": "Use RAG to look up information in the knowledgebase.",
        "tableName": "documents",
        "topK": 10,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1,
      "position": [
        448,
        128
      ],
      "id": "7cfb728c-7186-4ef4-bf3c-dc2533201091",
      "name": "Postgres PGVector Store5",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "=models/gemini-embedding-001"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "typeVersion": 1,
      "position": [
        528,
        288
      ],
      "id": "105d20a1-dd63-4d0e-bd67-eac5235ba6a8",
      "name": "Embeddings Google Gemini4",
      "credentials": {
        "googlePalmApi": {
          "id": "32bPIi6DQUfKBjyy",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "mode": "list",
          "cachedResultName": "accounts/fireworks/models/llama-v3p1-8b-instruct"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -464,
        48
      ],
      "id": "3085d035-e501-4d7c-bec0-0b6fb4a4d717",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "PqAOvGZFN7hnms72",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "accounts/fireworks/models/kimi-k2-instruct",
          "mode": "list",
          "cachedResultName": "accounts/fireworks/models/kimi-k2-instruct"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -176,
        112
      ],
      "id": "189834e8-42d9-49f9-ba9d-7b06e4e8c3ac",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "PqAOvGZFN7hnms72",
          "name": "OpenAi account"
        }
      }
    }
  ],
  "connections": {
    "AI Language Model2": {
      "main": [
        [
          {
            "node": "Process AI Response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start Loading Animation1": {
      "main": [
        [
          {
            "node": "AI Language Model3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Language Model3": {
      "main": [
        [
          {
            "node": "AI Language Model2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SerpAPI": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Webhook Entry1": {
      "main": [
        [
          {
            "node": "Filter Message Events1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Message Events1": {
      "main": [
        [
          {
            "node": "Message Processor1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Message Processor1": {
      "main": [
        [
          {
            "node": "Start Loading Animation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Response1": {
      "main": [
        [
          {
            "node": "Send Response to LINE1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory1": {
      "ai_memory": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "List Documents1": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get File Contents1": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Query Document Rows1": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Postgres PGVector Store5": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Google Gemini4": {
      "ai_embedding": [
        [
          {
            "node": "Postgres PGVector Store5",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Language Model3",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Language Model2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "6f55c6c26019d6bb3f208b12d13f9477c79d471cb1ff372dfc844c5d536dd8c4"
  }
}