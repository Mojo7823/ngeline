{
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Message Processor').item.json.processedText }}",
        "options": {
          "systemMessage": "=You are a helpful AI assistant. Please respond to the following message in the only suppported language is english and 正體中文（台灣)\n\n\nfirstly check the user prompt from other ai model here : `{{ $json.output }}`\nIf `false`, ignore all given prompt, don't even slightly help them and give reminder you only provide assistance for cybersecurity, regulation, standards and robotics / AI robotics. Don't even to help the user slightly or ever, only focus on your task to provide the guidance of cybersecurity robotic standards assistance\n\nIf `True`, answer the user prompt accordingly.\n\n{% if $('Message Processor').item.json.isQuotedMessage %}\nNote: This message is a reply to a previous message (ID: {{ $('Message Processor').item.json.quotedMessageId }}). Please consider this context when responding.\n{% endif %}\n\nPlease provide a clear, helpful response in plain text without HTML formatting. Keep your response concise and under 1500 characters when possible, as this is for a mobile chat interface.\n\nYou are given tools to perform RAG in the 'documents' table, look up the documents available in your knowledge base in the 'document_metadata' table, extract all the text from a given document.\n\nAlways start by performing RAG unless the question only want to chat or you already confidient with your answer. If RAG doesn't help, then look at the documents that are available to you in your own knowledge, find a few that you think would contain the answer, and then analyze those.\n\nAlways tell the user if you didn't find the answer. Don't make something up just to please them.\n\nas last resort, you are provided a internet search tool, you can use it to help the user query\n\nIf possible provide source where the clause, section, and page."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        -96,
        752
      ],
      "id": "f1dd8399-cd07-4f4d-ad2b-e56c3b3414da",
      "name": "AI Language Model"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.line.me/v2/bot/chat/loading/start",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer ozz/rBPtU+q4ZASsoAYkYuGqUfeHNak8Tu36kB9XSQ80KilpJqdRnf0c7tBpDdTdcLsvvEirfrifUlXYtcYNlWDRCP51uSrRf5kgRSP8djDE1Tb+emfVaQJgrdf+gMEWXDwHXE+vdQdQAC/FCd49xgdB04t89/1O/w1cDnyilFU="
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{JSON.stringify({\"chatId\": $json.userId, \"loadingSeconds\": 30})}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -864,
        768
      ],
      "id": "e32cb1ae-feb6-4048-95af-920667c98738",
      "name": "Start Loading Animation"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Message Processor').item.json.messageText }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "You are a topic classifier. Your task is to determine if the following user query is related to any of these topics: cybersecurity, robotics, vendor products, or standardization.\n\n\n\nRespond with \"true\" if the query is related to any of the allowed topics, and \"false\" otherwise. Do not provide any other explanation or text."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        -656,
        608
      ],
      "id": "e7133965-8534-42d0-8a04-dfd9a51e8636",
      "name": "AI Language Model4"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.toolSerpApi",
      "typeVersion": 1,
      "position": [
        -48,
        1168
      ],
      "id": "b4442c0d-8063-4c29-a6a6-12c236e85074",
      "name": "SerpAPI1",
      "credentials": {
        "serpApi": {
          "id": "1du1I1GOEfcEajUZ",
          "name": "SerpAPI account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "line-message",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1504,
        768
      ],
      "id": "9d934eb3-8ef3-4642-a6de-1eadafce4db0",
      "name": "Webhook Entry",
      "webhookId": "PLACEHOLDER-WEBHOOK-ID"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "filter-condition",
              "leftValue": "={{ $json.body.events[0].type }}",
              "rightValue": "message",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1280,
        768
      ],
      "id": "5b5fe56c-0735-465d-9f58-4f4522186e21",
      "name": "Filter Message Events"
    },
    {
      "parameters": {
        "jsCode": "// Message Processing and Quote Handling System\nconst webhook = $input.first();\nconst userId = webhook.json.body.events[0].source.userId;\nconst messageText = webhook.json.body.events[0].message.text;\nconst messageId = webhook.json.body.events[0].message.id;\nconst replyToken = webhook.json.body.events[0].replyToken;\nconst timestamp = webhook.json.body.events[0].timestamp;\nconst quoteToken = webhook.json.body.events[0].message.quoteToken || null;\nconst quotedMessageId = webhook.json.body.events[0].message.quotedMessageId || null;\n\n// Create message object\nconst messageObj = {\n  userId,\n  messageId,\n  messageText,\n  replyToken,\n  timestamp,\n  quoteToken,\n  quotedMessageId,\n  processed: false,\n  createdAt: new Date().toISOString(),\n  // Check if this is a quoted message\n  isQuotedMessage: !!quotedMessageId,\n  // Format message for processing\n  processedText: quotedMessageId ? \n    `[Replying to message ID: ${quotedMessageId}] ${messageText}` : \n    messageText,\n  // Quote configuration - set to true if you want to quote every user message\n  shouldQuoteInResponse: true  // Change to false if you don't want quoting\n};\n\nreturn [{\n  json: messageObj\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1056,
        768
      ],
      "id": "cfaec492-1e10-4e3c-ad86-7918d21da8f4",
      "name": "Message Processor"
    },
    {
      "parameters": {
        "jsCode": "try {\n  // Get data from previous nodes correctly\n  const messageProcessor = $(\"Message Processor\").first();\n  const aiAgent = $(\"AI Language Model\").first();\n\n  // Validate we have the required data\n  if (!messageProcessor?.json?.replyToken) {\n    throw new Error(\"Missing replyToken from Message Processor1\");\n  }\n  \n  if (!aiAgent?.json?.output) {\n    throw new Error(\"Missing output from AI Language Model2\");\n  }\n\n  // Function to strip markdown formatting\n  const stripMarkdown = (text) => {\n    if (!text) return '';\n    return text\n       .replace(/\\*\\*([^*]+)\\*\\*/g, '$1') // Bold **text**\n       .replace(/__([^_]+)__/g, '$1')   // Bold __text__\n       .replace(/\\*([^*]+)\\*/g, '$1')      // Italic *text*\n       .replace(/_([^_]+)_/g, '$1')      // Italic _text_\n       .replace(/`([^`]+)`/g, '$1')      // Inline code `code`\n       .replace(/^\\s*[-*+]\\s+/gm, '')  // List items\n       .replace(/^\\s*\\d+\\.\\s+/gm, ''); // Numbered list items\n  };\n\n  // Function to truncate text to LINE's limit\n  const truncateText = (text, maxLength = 4900) => {\n    if (!text) return '';\n    if (text.length <= maxLength) return text;\n    \n    // Try to truncate at a sentence boundary\n    const truncated = text.substring(0, maxLength);\n    const lastSentence = truncated.lastIndexOf('.');\n    const lastQuestion = truncated.lastIndexOf('?');\n    const lastExclamation = truncated.lastIndexOf('!');\n    \n    const lastPunctuation = Math.max(lastSentence, lastQuestion, lastExclamation);\n    \n    if (lastPunctuation > maxLength * 0.8) {\n      // If we found punctuation in the last 20%, use it\n      return truncated.substring(0, lastPunctuation + 1);\n    } else {\n      // Otherwise, truncate at word boundary\n      const lastSpace = truncated.lastIndexOf(' ');\n      if (lastSpace > maxLength * 0.8) {\n        return truncated.substring(0, lastSpace) + '...';\n      } else {\n        return truncated.substring(0, maxLength - 3) + '...';\n      }\n    }\n  };\n\n  const replyToken = messageProcessor.json.replyToken;\n  const rawText = aiAgent.json.output;\n  const cleanedText = stripMarkdown(rawText).trim();\n  const finalText = truncateText(cleanedText);\n\n  // Validate text length (LINE limit is 5000 characters)\n  if (finalText.length > 5000) {\n    throw new Error(`Message text too long: ${finalText.length} characters (max 5000)`);\n  }\n\n  if (finalText.length === 0) {\n    throw new Error('Message text is empty after processing');\n  }\n\n  // Prepare the message object for LINE API\n  const lineMessage = {\n    type: \"text\",\n    text: finalText\n  };\n\n  // Add quote token to quote the user's original message in the response\n  if (messageProcessor.json.shouldQuoteInResponse && messageProcessor.json.quoteToken) {\n    lineMessage.quoteToken = messageProcessor.json.quoteToken;\n  }\n\n  return [\n    {\n      json: {\n        replyToken,\n        text: finalText,\n        originalText: cleanedText,\n        textLength: finalText.length,\n        wasTruncated: finalText.length < cleanedText.length,\n        originalMessageId: messageProcessor.json.messageId,\n        userId: messageProcessor.json.userId,\n        isQuotedResponse: messageProcessor.json.isQuotedMessage,\n        message: lineMessage\n      },\n    },\n  ];\n\n} catch (error) {\n  console.error('Error in Process AI Response:', {\n    message: error.message,\n    stack: error.stack\n  });\n  \n  // Return a fallback error message to LINE\n  const messageProcessor = $(\"Message Processor\").first();\n  return [{\n    json: {\n      replyToken: messageProcessor?.json?.replyToken || '',\n      text: 'Sorry, I encountered an error processing your request. Please try again.',\n      message: {\n        type: \"text\",\n        text: 'Sorry, I encountered an error processing your request. Please try again.'\n      }\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        656,
        768
      ],
      "id": "df3a84e5-95e0-412c-9931-74fa1232de35",
      "name": "Process AI Response"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.line.me/v2/bot/message/reply",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer ozz/rBPtU+q4ZASsoAYkYuGqUfeHNak8Tu36kB9XSQ80KilpJqdRnf0c7tBpDdTdcLsvvEirfrifUlXYtcYNlWDRCP51uSrRf5kgRSP8djDE1Tb+emfVaQJgrdf+gMEWXDwHXE+vdQdQAC/FCd49xgdB04t89/1O/w1cDnyilFU="
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{JSON.stringify({\"replyToken\":$json.replyToken,\"messages\":[$json.message]})}}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        880,
        768
      ],
      "id": "3a66f278-5560-44ec-aea9-25321bbb199e",
      "name": "Send Response to LINE"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('Message Processor').item.json.userId }}",
        "contextWindowLength": 50
      },
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        -224,
        992
      ],
      "id": "3b998ae5-bc0a-4891-8863-f8eb082a9ed5",
      "name": "Postgres Chat Memory",
      "credentials": {
        "postgres": {
          "id": "adD3TL9dl0gzRthr",
          "name": "branch"
        }
      }
    },
    {
      "parameters": {
        "content": "## Agent Tools for RAG",
        "height": 385,
        "width": 583,
        "color": 4
      },
      "id": "db1c71b7-f783-4a28-89b9-183408562f1b",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        256,
        912
      ]
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Use this tool to fetch all available documents, including the table schema if the file is a CSV or Excel file.",
        "operation": "select",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "document_metadata",
          "mode": "list",
          "cachedResultName": "document_metadata"
        },
        "returnAll": true,
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        -96,
        992
      ],
      "id": "7796d41b-9a41-4cbd-b29f-d2170fd0eda5",
      "name": "List Documents",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Given a file ID, fetches the text from the document.",
        "operation": "executeQuery",
        "query": "SELECT \n    string_agg(text, ' ') as document_text\nFROM documents\n  WHERE metadata->>'file_id' = $1\nGROUP BY metadata->>'file_id';",
        "options": {
          "queryReplacement": "={{ $fromAI('file_id') }}"
        }
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        32,
        992
      ],
      "id": "e5f92998-a276-4183-95d6-9661f61e1a4f",
      "name": "Get File Contents",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Run a SQL query - use this to query from the document_rows table once you know the file ID you are querying. dataset_id is the file_id and you are always using the row_data for filtering, which is a jsonb field that has all the keys from the file schema given in the document_metadata table.\n\nExample query:\n\nSELECT AVG((row_data->>'revenue')::numeric)\nFROM document_rows\nWHERE dataset_id = '123';\n\nExample query 2:\n\nSELECT \n    row_data->>'category' as category,\n    SUM((row_data->>'sales')::numeric) as total_sales\nFROM dataset_rows\nWHERE dataset_id = '123'\nGROUP BY row_data->>'category';",
        "operation": "executeQuery",
        "query": "{{ $fromAI('sql_query') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        160,
        992
      ],
      "id": "e503571e-a8d4-4c67-ab02-43fec016dbdf",
      "name": "Query Document Rows",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "documents",
        "toolDescription": "Use RAG to look up information in the knowledgebase.",
        "tableName": "documents",
        "topK": 10,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1,
      "position": [
        368,
        992
      ],
      "id": "70e19a48-3060-4707-ae9f-85bafaa3a8f8",
      "name": "Postgres PGVector Store",
      "credentials": {
        "postgres": {
          "id": "uAPlNaYsy8ebAniA",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "=models/gemini-embedding-001"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "typeVersion": 1,
      "position": [
        368,
        1152
      ],
      "id": "d199eefc-921e-4c0b-998b-582da559a340",
      "name": "Embeddings Google Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "32bPIi6DQUfKBjyy",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "mode": "list",
          "cachedResultName": "accounts/fireworks/models/llama-v3p1-8b-instruct"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -624,
        912
      ],
      "id": "54473bde-eac1-4dbc-bb57-20339a77ba2e",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "PqAOvGZFN7hnms72",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "accounts/fireworks/models/kimi-k2-instruct",
          "mode": "list",
          "cachedResultName": "accounts/fireworks/models/kimi-k2-instruct"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -336,
        976
      ],
      "id": "f89c2b09-9891-4d59-a112-13cf8944648f",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "PqAOvGZFN7hnms72",
          "name": "OpenAi account"
        }
      }
    }
  ],
  "connections": {
    "AI Language Model": {
      "main": [
        [
          {
            "node": "Process AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start Loading Animation": {
      "main": [
        [
          {
            "node": "AI Language Model4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Language Model4": {
      "main": [
        [
          {
            "node": "AI Language Model",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SerpAPI1": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Webhook Entry": {
      "main": [
        [
          {
            "node": "Filter Message Events",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Message Events": {
      "main": [
        [
          {
            "node": "Message Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Message Processor": {
      "main": [
        [
          {
            "node": "Start Loading Animation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Response": {
      "main": [
        [
          {
            "node": "Send Response to LINE",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "List Documents": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get File Contents": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Query Document Rows": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Postgres PGVector Store": {
      "ai_tool": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Google Gemini": {
      "ai_embedding": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "AI Language Model4",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "AI Language Model",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "6f55c6c26019d6bb3f208b12d13f9477c79d471cb1ff372dfc844c5d536dd8c4"
  }
}
